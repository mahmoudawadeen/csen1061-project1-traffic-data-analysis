---
title: Traffic Data Analysis
output: html_document
---
```{r include=FALSE}
library(ggplot2)
library(dplyr)
library(knitr)
library(BSDA)
```
# Introduction
Bey2ollak is an application for people to exchange info about traffic that uses crowd-sourcing, social interaction, localization to provide users with information about road statuses.

The data provided is crawled every 30 minutes from the web version of bey2ollak, which basically means every 30 minutes we have a screenshot of the whole data displayed to users.

# Load data
```{r cache = TRUE}
data <- read.csv("traffic-data.csv")
```
# Data exploration
first we are going to take an overview look at the data
```{r cache = TRUE}
data %>% dim
data %>% glimpse 
data %>% head
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter() %>%kable
```

First there are columns that are used for storing ads which are not useful. Also It seems that we have rd.cl and rd.rp.type that are constant for all the rows which is not very useful for analysis purposes. so in order to limit or data to columns that are more significant those columns would be dropped.

It's also clear that we have some variables with 2 unique values which maybe boolean values, also we have large values of nas which will be addressed later on.
```{r cache = TRUE}
data <- data %>% select(-c(2:14),-rd.cl,-rd.rp.type)
info <- info %>% filter(unique > 1)
```

# Column symantics

Until now the our understanding of columns in the data is as follows which will be stored in a data frame to easily update it as we go:

```{r cache = TRUE}
sym <- data.frame(Variables=names(data),
                  Symantic= c(
                    "The date the data was crawled on",
                    "seems like road names but needs some organizing",
                    "road ids",
                    "unkown",
                    "from the name we can guess this column relates to hours",
                    "another guess relates to minutes",
                    "unkown however it's known to hold a 2 unique values which is suspected to be a boolean",
                    "obvioulsy this has something to do with",
                    "same as rd.new",
                    "same as rd.new",
                    "seems like human names",
                    "also seems like human names",
                    "same as rd.hr",
                    "same as rd.mn",
                    "unkown",
                    "user comments",
                    "comment ids",
                    "same as rd.rpImg",
                    "same as rd.rpImg"))
sym %>% kable
```

From taking a look at the bey2ollak web version, Each road is consisted of sub roads which have statuses, time stamp, some reports posted on it and each report has a status, comment, time stamp and optional image attached. Users who report have profile images, usernames and full names. A road status is determined by the reports posted on it, so for the road time stamp it will be equal to the latest report time stamp. As for the data crawled, we can say that rd is a road and rp is a report.

# Cleaning data
## Duplicate and mobile application columns
We are going to start with duplicate columns suspects rd.rp.nm and rd.rp.fullnm. Let's take a look on some examples from this two columns
```{r cache = TRUE}
data %>% select(rd.rp.nm,rd.rp.fullnm) %>% unique %>% head(10) %>% kable
```

we can notice that the are two unique names fa3el kheir and bey2ollakgps and there are also NAs in fullnm while 0 NAs in nm.

```{r cache = TRUE}
data %>% select(rd.rp.nm,rd.rp.fullnm) %>% filter(is.na(rd.rp.fullnm)) %>% unique %>% head(10) %>% kable
```

upon some investigation on bey2ollak fa3el kheir is a feature where users can report anonymously and bey2ollakgps is auto reporting of road status using gps. Also as seen some users don't have full names recorded on bey2ollak, from this info we can deduce that rd.rp.fullnm and rd.rp.nm are duplicated where rd.rp.nm doesn't contain any NAs so rd.rp.fullnm will be dropped.

After taking a look for the web version front end source code a js file was found with some insight on column semantics where rd.new , rd.strq, rd.cmrq where not used which concludes that these are just flags used for mobile applications. Which makes has no effect on the data. It also confirms some guesses made previously, so we will update the column semantic table and also rename some columns.
```javascript
$(xml).find("rp").each(function () {

        stid = $('stid', $(this)).text();
        ustid = "";

        if($('stid', $(this)).size() > 1) {

            stid = $('stid', $(this)).eq(0).text();
            ustid = $('stid', $(this)).eq(1).text();

        }

        comments.push({
            userName: $('nm', $(this)).text(), 
            comment: $('cm', $(this)).text(),
            status: stid,
            ustatus: ustid,
            logo: $('img', $(this)).text(),
            image: $('rpImg', $(this)).text(),
            hour: $('hr', $(this)).text(),
            min: $('mn', $(this)).text()
        });    


    });
```

```{r cache = TRUE}
data <- data %>% select(-rd.rp.fullnm,-rd.new,-rd.strq,-rd.cmrq)
data <- data %>% rename(road_status = rd.stid,road_hours=rd.hr,road_minutes=rd.mn,reporter=rd.rp.nm,report_hours=rd.rp.hr,report_minutes=rd.rp.mn,report_status=rd.rp.stid,report_comment=rd.rp.cm,report_comment_id=rd.rp.cmid)
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
```

Let's also change the crawl date to a more readable format.

```{r cache = TRUE}
data$crawl_date <- as.POSIXct(strptime(data$crawl_date,  format="%a %b %d %H:%M:%S UTC %Y", tz="UTC"))
```

## Duplicate rows
Taking into consideration the nature of how the data is crawled duplicate rows may occur since after half an hour from the last crawl the number of new reports on a road may not replace all the previously crawled reports.

The number of duplicated comments id are:

```{r cache = TRUE}
sum(duplicated(data$report_comment_id))
```

an example on duplicated ids :

```{r cache = TRUE}
data %>% filter(report_comment_id==head(data$report_comment_id[duplicated(data$report_comment_id)],1)) %>% select(-road_hours,-road_minutes,-report_hours,-report_minutes,-rd.rp.rpImg,-rd.rp.img) %>% kable
```

So it seems that we have the same report duplicated three times one every half an hour, Which we can conclude that we can remove duplicates using comment id.

The number of rows before removing duplicates:
```{r cache = TRUE}
data %>% nrow
```

The number of duplicates now:
```{r cache = TRUE}
data <- data %>% filter(!duplicated(data$report_comment_id))
sum(duplicated(data$report_comment_id))
```

The number of rows after removing duplicates:
```{r}
data %>% nrow
```

## NAs investigation

```{r}
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter %>% kable
```

The number of NAs in road_hours and road_minutes is equal which means that the time stamp of these roads wasn't available when the data was crawled and there's no method for retrieving and also since they are only `r info %>%filter(variable=='road_hours')%>%select(unique)*100/nrow(data)`% of the data removing these rows won't make a significant change.

```{r cache = TRUE}
data <- data %>% filter(!is.na(road_hours))
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter %>% kable
```

Bey2ollak doesn't show the status of the road if the last report was more then 2 hours ago had status from 1 to 5, this piece of info may help us to decrease the number of NAs in road_status. First let's investigate this piece of info.

We need actual report and road time.

```{r cache = TRUE}
data <- (data %>% mutate(report_date=crawl_date - (report_hours*60*60) - (report_minutes * 60) ))
data <- (data %>% mutate(road_date=crawl_date - (road_hours*60*60) - (road_minutes * 60) ))
```
Roads which have NAs and the latest report is available with status less then 6
```{r cache = TRUE}
data %>% filter(is.na(road_status) & road_hours>1 & report_status<6 & report_date == road_date)%>%nrow
```
Which will take a new status 11
```{r cache = TRUE}
data <- data %>% mutate(road_status=replace(road_status,is.na(road_status) & road_hours>1 & report_status<6 & report_date == road_date,11))
```
Then we need to reflect the new status to equivalent rows which will cut down the number of NAs in the road_status by approximately half
```{r cache = TRUE}
road_status_11 <- data%>%filter(road_status==11)
data <- data %>% mutate(road_status = replace(road_status,is.na(road_status) & road_date %in% road_status_11$road_date,11))
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter %>% kable

```
let's take a look if we still have NAs in road status where we have the latest report in the data.
```{r cache = TRUE}
data %>% filter(is.na(road_status) & road_date==report_date) %>%select(-road_date,-report_date,-road_status,-road_hours,-report_hours,-road_minutes,-report_minutes) %>% kable
```

The first record is a little bit weird since there's no known reasons for it to not have road_status other than it has something to do with bey2ollak's calculations. let's investigate more into this column.
```{r}
temp1 <- data %>% filter(is.na(road_status) & report_date == road_date)
data%>% filter(crawl_date==temp1$crawl_date[1] & rd.ri == temp1$rd.ri[1]) %>%select(-report_comment_id,-rd.rp.rpImg,-rd.rp.img,-report_date,-road_date,-report_minutes,-report_hours,-road_minutes,-road_hours) %>% kable()
```

It seems that it's the only record recorded in this snapshot about this road. Which maybe be cause by so many reasons, however looking for the reason would be an overkill since it's only one row.

For the other rows it seems that the road_hours is more than two hours, however, the status is more than 5 which assumed to not cause any NAs in the road_status. Let's give it a look, we will try to simulate the same scenario or even a more extreme one and take a look of what the data has to say about this scenario.

```{r}
data %>% filter(road_status>5&road_status<11 & road_hours>13 & report_date == road_date) %>%select(-report_comment_id,-rd.rp.rpImg,-rd.rp.img,-report_date,-road_date,-report_minutes,-report_hours)%>%head(20)%>% kable()
```

For some reason there are road scenarios where the road_hours is more than two, the road_status is more than 5 and didn't cause NAs, this has something to do with the way bey2ollak calculates the road_status. So in order to avoid making wrong assumptions and messing the data, NAs in road_status will be dropped since they only form `r sum(is.na(data$road_status))*100/nrow(data) `%.
```{r}
data <- data%>%filter(!is.na(road_status))
```
Bey2ollak enables users to comment on roads without adding a report_status which resulted in having NAs in the report_status.these comments will take report_status 12.
```{r}
data <- data %>%mutate(report_status=replace(report_status,is.na(report_status),12))
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter %>% kable
```

After looking into bey2ollak images, it was found that bey2ollak has three types of images: user profile images, images attached to reports and road images when the latest report has an image attached to it, which are represented respectively in our data rd.rp.img , rd.rp.rpImg and rd.img. let's rename these columns for better reading and discard the values with either true or false since these values are used for retrieving the images from bey2ollak database.
```{r}
data <- data %>% rename(reporter_image=rd.rp.img,report_image=rd.rp.rpImg,road_image=rd.img)

data <- data %>% mutate(report_image=replace(report_image,!is.na(report_image),TRUE)) %>% mutate(report_image=replace(report_image,is.na(report_image),FALSE)) %>% mutate(reporter_image=replace(reporter_image,!is.na(reporter_image),TRUE))%>%mutate(reporter_image=replace(reporter_image,is.na(reporter_image),FALSE)) %>% mutate(road_image=replace(road_image,is.na(road_image),FALSE))

info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter %>% kable
```

After this step all the NAs from the data were removed and we are ready to continue analysis.

# Discriptive statics
Since the data was crawled from a different timezone we need to convert the timezone of all the dates to be consistent with Cairo timings.
```{r cache=TRUE}
data<- data%>% mutate(crawl_date=crawl_date+2*60*60,report_date=report_date+2*60*60,road_date=road_date+2*60*60)
```
And then we will divide the report times we have into 30 minutes time intervals and plot them against the number of the reports in an interval.
```{r cache=TRUE}
data <-data %>% mutate(interval = strftime(cut(data$report_date,breaks="30 min"),format="%H:%M"))
data %>% group_by(interval) %>% summarize(reports=length(report_comment_id))%>%head %>% kable
```
Now we can take a look for the number of reports at each time interval it's expected to have two peeks demonstrating the two rush hours in the normal day life going to and coming back from work.
```{r cache = TRUE}
data %>% group_by(interval) %>% summarize(reports=length(report_comment_id))%>%ggplot(aes(x=interval, y=reports)) + geom_bar(stat='identity')+theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

As expected we have two peaks around 8-9 am and another wider peak around 4-7 pm.

Now let's take a look on the 30 most reported roads taking into consideration the road_status from 1 to 5. 


```{r cache = TRUE}
data %>% filter(road_status<6) %>% group_by(rd.nm) %>% summarize(stat=mean(road_status),reports=length(report_comment_id)) %>%arrange(desc(reports))%>% head(30) %>% kable()
```

```{r cache = TRUE}
data %>% filter(road_status<6) %>% group_by(rd.nm) %>% summarize(stat=mean(road_status),reports=length(report_comment_id)) %>%arrange(desc(reports)) %>% head(30) %>% ggplot(aes(x=rd.nm, y=stat)) + geom_bar(stat='identity')+theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

It seems that some roads have a mean of approximately 3 while other have approximately 2 which is quite strange since we all now that roads in Cairo are congested, keeping in mind that this plot is across the whole day.

We will give a rough estimate of day to be starting from 6 am to 8 pm.
```{r}
data <- data %>% mutate(day_time = ifelse(strptime(interval,format="%H:%M") < strptime("20:00",format="%H:%M") & strptime(interval,format="%H:%M")>strptime("6:00",format="%H:%M"),"Day","Night"))
```
And now we can compare the means between night and day time.
```{r}
data %>% filter(road_status<6) %>% group_by(day_time) %>% summarize(reports=length(report_comment_id)) %>% kable
```

it's seems people are more active at day time which is consistent with the peaks we found. What about the average road status.

```{r cache = TRUE}
data %>% filter(road_status<6 &day_time=="Day") %>% group_by(rd.nm) %>% summarize(reports_day=length(report_comment_id),stat_day=mean(road_status)) %>% arrange(desc(reports_day)) %>% head(10) %>% kable

data %>% filter(road_status<6 &day_time=="Night") %>% group_by(rd.nm) %>% summarize(reports_night=length(report_comment_id),stat_night=mean(road_status)) %>% arrange(desc(reports_night)) %>% head(10) %>% kable()
```

Now let's plot at day
```{r cache = TRUE}
data %>% filter(road_status<6 &day_time=="Day") %>% group_by(rd.nm) %>% summarize(reports_day=length(report_comment_id),stat_day=mean(road_status)) %>% arrange(desc(reports_day)) %>% head(10) %>% ggplot(aes(x=rd.nm, y=stat_day)) + geom_bar(stat='identity')+theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Now the night
```{r cache = TRUE}
data %>% filter(road_status<6 &day_time=="Night") %>% group_by(rd.nm) %>% summarize(reports_night=length(report_comment_id),stat_night=mean(road_status)) %>% arrange(desc(reports_night)) %>% head(10) %>%ggplot(aes(x=rd.nm, y=stat_night)) + geom_bar(stat='identity')+theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The data suggests that roads are less congested at night than day which also consistent with the peaks.

Now let's take a look at days of the week
```{r cache = TRUE}
data <- data %>% mutate(weekday=weekdays(report_date))

data %>% group_by(weekday) %>% summarize(reports = length(report_comment_id))%>%mutate(percentage = reports*100/sum(reports)) %>% ggplot(aes(x = "",y=percentage, fill = factor(weekday))) + geom_bar(width = 1,stat="identity") +geom_text(aes(y=cumsum(percentage)-percentage/2,label=round(percentage,3)))+ coord_polar(theta = "y")
```

The is no signficant difference in the number of reports between the day, however, it's clear the thursday is the most while friday is the least reported day.

Until now we didn't talk about who reports so let's add two more features anonymous and gps.
```{r cache = TRUE}
data <- data %>% mutate(anonymous=reporter=="fa3el kheir",gps = reporter == "bey2ollakgps")
data %>% mutate(reporter_type=ifelse(anonymous,"fa3el kheir",ifelse(gps,"bey2ollakgps","user")))%>% group_by(reporter_type) %>% summarize(reports = length(report_comment_id))%>%mutate(percentage = reports*100/sum(reports)) %>% ggplot(aes(x = "",y=percentage, fill = factor(reporter_type))) + geom_bar(width = 1,stat="identity") +geom_text(aes(y=cumsum(percentage)-percentage/2,label=round(percentage,3)))+ coord_polar(theta = "y")
```

Users have the dominance in report percentage where a little portion of the users prefer to report anonymously.


```{r cache = TRUE}
data %>% group_by(report_status) %>% summarize(reports = length(report_comment_id)) %>% ggplot(aes(x=report_status, y=reports)) + geom_bar(stat='identity')+theme(axis.text.x = element_text(angle = 90, hjust = 1))+scale_x_discrete(breaks=seq(1,12,1))
```

```{r cache = TRUE}
data %>% group_by(road_status) %>% summarize(reports = length(road_status)) %>% ggplot(aes(x=road_status, y=reports)) + geom_bar(stat='identity')+theme(axis.text.x = element_text(angle = 90, hjust = 1))+scale_x_discrete(breaks=seq(1,11,1))
```

The graph of the number of reports per road status is experincing the same behavior as the number of reports per report status which says that the road status is dependent on the report status.

Now let's look on frequency of reporting and how much a road is update

```{r cache = TRUE}
data %>% ggplot(aes(x=day_time, y=report_hours+report_minutes/60)) + geom_boxplot() +
    stat_summary(fun.y=mean, geom="point", shape=5, size=4) + scale_y_continuous(breaks = round(seq(min(data$report_hours+data$report_minutes/60), max(data$report_hours+data$report_minutes/60), by = 5),1))
```

We can see that we have a lot of outliers due to user inactivity.
# Inferential data analysis
```{r cache = TRUE}
sample_means <- lapply(1:1000, function(rep) {data %>%filter(road_status<6) %>% sample_n(1000,replace=FALSE) %>% summarize(m=mean(road_status))})%>%unlist()
hist(sample_means)
z.test(sample_means, sigma.x = sd(sample_means), conf.level = 0.95)
```

```{r cache = TRUE}
sample_means <- lapply(1:1000, function(rep) {data %>%filter(road_status<6) %>% sample_n(1000,replace=TRUE) %>% summarize(m=mean(road_hours+road_minutes/60))})%>%unlist()
hist(sample_means)
z.test(sample_means, sigma.x = sd(sample_means), conf.level = 0.95)
```