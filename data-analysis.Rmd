---
title: Traffic Data Analysis
output: html_document
---
```{r include=FALSE}
library(ggplot2)
library(dplyr)
library(knitr)
```
# Introduction
Bey2ollak is an application for people to exchange info about traffic that uses crowd-sourcing, social interaction, localization to provide users with information about road statuses.

The data provided is crawled every 30 minutes from the web version of bey2ollak, which basically means every 30 minutes we have a screenshot of the whole data displayed to users.

# Load data
```{r cache = TRUE}
data <- read.csv("traffic-data.csv")
```
# Data exploration
first we are going to take an overview look at the data
```{r}
data %>% dim
data %>% glimpse 
data %>% head
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter() %>%kable
```

First there are columns that are used for storing ads which are not useful. Also It seems that we have rd.cl and rd.rp.type that are constant for all the rows which is not very useful for analysis purposes. so in order to limit or data to columns that are more significant those columns would be dropped.

It's also clear that we have some variables with 2 unique values which maybe boolean values, also we have large values of nas which will be addressed later on.
```{r}
data <- data %>% select(-c(2:14),-rd.cl,-rd.rp.type)
info <- info %>% filter(unique > 1)
```

# Column symantics

Until now the our understanding of columns in the data is as follows which will be stored in a data frame to easily update it as we go:

```{r}
sym <- data.frame(Variables=names(data),
                  Symantic= c(
                    "The date the data was crawled on",
                    "seems like road names but needs some organizing",
                    "road ids",
                    "unkown",
                    "from the name we can guess this column relates to hours",
                    "another guess relates to minutes",
                    "unkown however it's known to hold a 2 unique values which is suspected to be a boolean",
                    "obvioulsy this has something to do with",
                    "same as rd.new",
                    "same as rd.new",
                    "seems like human names",
                    "also seems like human names",
                    "same as rd.hr",
                    "same as rd.mn",
                    "unkown",
                    "user comments",
                    "comment ids",
                    "same as rd.rpImg",
                    "same as rd.rpImg"))
sym %>% kable
```

From taking a look at the bey2ollak web version, Each road is consisted of sub roads which have statuses, timestamp, some reports posted on it and each report has a status, comment, timestamp and optional image attached. Users who report have profile images, usernames and full names. A road status is determined by the reports posted on it, so for the road timestamp it will be equal to the latest report timestamp. As for the data crawled, we can say that rd is a road and rp is a report.

# Cleaning data
## Duplicate and mobile application columns
We are going to start with duplicate columns suspects rd.rp.nm and rd.rp.fullnm. Let's take a look on some examples from this two columns
```{r}
data %>% select(rd.rp.nm,rd.rp.fullnm) %>% unique %>% head(10) %>% kable
```

we can notice that the are two unique names fa3el kheir and bey2ollakgps and there are alos NAs in fullnm while 0 NAs in nm.

```{r}
data %>% select(rd.rp.nm,rd.rp.fullnm) %>% filter(is.na(rd.rp.fullnm)) %>% unique %>% head(10) %>% kable
```

upon some invastigation on bey2ollak fa3el kheir is a feature where users can report anonmously and bey2ollakgps is auto reporting of road status using gps. Also as seen some users don't have full names recorded on bey2ollak, from this info we can deduce that rd.rp.fullnm and rd.rp.nm are duplicated where rd.rp.nm doesn't contain any NAs so rd.rp.fullnm will be dropped.

After taking a look for the web version frontend source code a js file was found with some insight on column symantics where rd.new , rd.strq, rd.cmrq where not used which concludes that these are just flags used for mobile applications. Which makes has no effect on the data. It also confirms some guesses made previously, so we wil update the column symantic table and also rename some columns.
```javascript
$(xml).find("rp").each(function () {

        stid = $('stid', $(this)).text();
        ustid = "";

        if($('stid', $(this)).size() > 1) {

            stid = $('stid', $(this)).eq(0).text();
            ustid = $('stid', $(this)).eq(1).text();

        }

        comments.push({
            userName: $('nm', $(this)).text(), 
            comment: $('cm', $(this)).text(),
            status: stid,
            ustatus: ustid,
            logo: $('img', $(this)).text(),
            image: $('rpImg', $(this)).text(),
            hour: $('hr', $(this)).text(),
            min: $('mn', $(this)).text()
        });    


    });
```

```{r}
data <- data %>% select(-rd.rp.fullnm,-rd.new,-rd.strq,-rd.cmrq)
data <- data %>% rename(road_status = rd.stid,road_hours=rd.hr,road_minutes=rd.mn,reporter=rd.rp.nm,report_hours=rd.rp.hr,report_minutes=rd.rp.mn,report_status=rd.rp.stid,report_comment=rd.rp.cm,report_comment_id=rd.rp.cmid)
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
```

Let's also change the crawl date to a more readable format.

```{r}
data$crawl_date <- as.POSIXct(strptime(data$crawl_date,  format="%a %b %d %H:%M:%S UTC %Y", tz="UTC"))
typeof(data$crawl_date)
```

## Duplicate rows
Taking into consideration the nature of how the data is crawled duplicate rows may occur since after half an hour from the last crawl the number of new reports on a road may not replace all the previously crawled reports.

The number of duplicated comments id are:

```{r}
sum(duplicated(data$report_comment_id))
```

an example on duplicated ids :

```{r}
data %>% filter(report_comment_id==head(data$report_comment_id[duplicated(data$report_comment_id)],1)) %>% select(-road_hours,-road_minutes,-report_hours,-report_minutes,-rd.rp.rpImg,-rd.rp.img) %>% kable
```

So it seems that we have the same report duplicated three times one every half an hour, Which we can conclude that we can remove duplicates using comment id.

The number of rows before removing duplicates:
```{r}
data %>% nrow
```

The number of duplicates now:
```{r}
data <- data %>% filter(!duplicated(data$report_comment_id))
sum(duplicated(data$report_comment_id))
```

The number of rows after removing duplicates:
```{r}
data %>% nrow
```

## NAs investigation

```{r}
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter %>% kable
```

The number of NAs in road_hours and road_minutes is equal which means that the timestamp of these roads wasn't available when the data was crawled and there's no method for retriving and also since they are only `r info %>%filter(variable=='road_hours')%>%select(unique)*100/nrow(data)`% of the data removing these rows won't make a significant change.

```{r}
data <- data %>% filter(!is.na(road_hours))
info<-data.frame(variable=names(data),nas=rapply(data,function(x)sum(is.na(x))),unique=rapply(data,function(x) length(unique(x))))
info %>% filter %>% kable
```
